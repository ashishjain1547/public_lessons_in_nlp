<head>
    <script crossorigin="anonymous" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
    
    <!-- Google AdSense Using Machine Learning Code -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-3071098372371409",
            enable_page_level_ads: true
        });
    </script>

    <style>
        pre {
            white-space: pre-wrap;
            white-space: -moz-pre-wrap;
            white-space: -pre-wrap;
            white-space: -o-pre-wrap;
            word-wrap: break-word;
        }
    </style>
</head>
<!-- End of 'Personal Posts Menu Template For Copy-Paste'. It started from the top of the page from <HEAD> tag. -->

<pre>
As of Jan 2020, The SOAN code requires Python 2.7.
We would soon have to migrate this code Python 3.X because Python 2.7 will reach the end of its life on January 1st, 2020.

STEP 1: We will create a Python 2.7.16 environment and a kernel for Anaconda as shown in this link "https://survival8.blogspot.com/p/installing-new-kernel-in-jupyter.html"

STEP 2: Install the necessary Python packages.

For this, I am generating a requirement.txt file using "pip freeze" command in my already set up environment as shown below:

<b>(py_2716) D:\>pip freeze > requirements.txt </b>

On your machine that you need to set up, run the following command from directory having the "requirements.txt" file.

<b>(py_2716) D:\>pip install -r requirements.txt </b>

A "pip freeze" of my py_2716 environment shows following packages:

backports-abc==0.5
backports.csv==1.0.7
backports.functools-lru-cache==1.5
backports.shutil-get-terminal-size==1.0.0
beautifulsoup4==4.7.1
certifi==2019.6.16
chardet==3.0.4
cheroot==6.5.5
CherryPy==17.4.2
colorama==0.4.1
contextlib2==0.5.5
cycler==0.10.0
decorator==4.4.0
emoji==0.5.2
enum34==1.1.6
feedparser==5.2.1
future==0.17.1
futures==3.3.0
idna==2.8
ipykernel==4.10.0
ipython==5.8.0
ipython-genutils==0.2.0
jaraco.functools==2.0
jupyter-client==5.3.1
jupyter-core==4.5.0
kiwisolver==1.1.0
lxml==4.3.4
matplotlib==2.2.4
more-itertools==5.0.0
mysqlclient==1.4.2
nltk==3.4.4
numpy==1.16.4
palettable==3.2.0
pandas==0.24.2
pathlib2==2.3.4
Pattern==3.6
pdfminer==20140328
pickleshare==0.7.5
Pillow==6.1.0
portend==2.5
prompt-toolkit==1.0.16
Pygments==2.4.2
pyparsing==2.4.0
python-dateutil==2.8.0
python-docx==0.8.10
pytz==2019.1
pywin32==224
pyzmq==18.0.2
regex==2019.6.8
requests==2.22.0
scandir==1.10.0
scikit-learn==0.20.3
scipy==1.2.2
seaborn==0.9.0
simplegeneric==0.8.1
singledispatch==3.4.0.3
six==1.12.0
sklearn==0.0
soupsieve==1.9.2
tempora==1.14.1
tornado==5.1.1
traitlets==4.3.2
urllib3==1.25.3
wcwidth==0.1.7
win-unicode-console==0.5
wincertstore==0.2
wordcloud==1.5.0
zc.lockfile==1.4

STEP 3: How we have generated data?

We have exported a particular group chat for this demo. This is done via the email option that comes in WhatsApp app. Exported file is a text file "WhatsApp Chat with Cousins (201910-201912).txt".

STEP 4:
The entire code is present on this Google drive link: https://drive.google.com/open?id=1r8oY5BhAlsG0womnWH5awQMdLqSKQebO
</pre>
<span style="display: none">Tags: Technology,Natural Language Processing,</span>